{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **IMPORTS AND SETUP**</p>\n\nFor this project, we have primarily used 3 libraries - \n 1. pyTorch, as the deep learning framework\n 2. music21, to fetch the notes from the dataset.\n","metadata":{}},{"cell_type":"code","source":"#Installing dependencies\n!pip install music21\n!apt-get install -y lilypond","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing helping libraries\nimport tensorflow as tf\nimport numpy as np \nimport os\nimport pandas as pd \nfrom collections import Counter\nimport random\nimport IPython\nfrom IPython.display import Image, Audio\nimport music21\nfrom music21 import *\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.optimizers import Adamax\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n%matplotlib inline\nimport sys\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(\"ignore\")\nnp.random.seed(42)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-03T16:28:28.670710Z","iopub.execute_input":"2023-03-03T16:28:28.670927Z","iopub.status.idle":"2023-03-03T16:28:34.721203Z","shell.execute_reply.started":"2023-03-03T16:28:28.670900Z","shell.execute_reply":"2023-03-03T16:28:34.720453Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Dataset\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data.dataloader import DataLoader\nimport torchvision\nimport torchvision.transforms as tt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-03-03T16:30:26.958942Z","iopub.execute_input":"2023-03-03T16:30:26.959306Z","iopub.status.idle":"2023-03-03T16:30:31.627065Z","shell.execute_reply.started":"2023-03-03T16:30:26.959262Z","shell.execute_reply":"2023-03-03T16:30:31.626199Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **LOADING AND PARSING DATA**</p>\n\nFor this project, I will be using MIDI files of classical piano music. The dataset includes various artists. I will be working with Frédéric Chopin's compositions. \n \n* First of all, I make a list of all the songs in the Chopin folder parsed as music21 stream.\n\n* Then I will be creating a function to extract chords and notes out of the data creating a corpus.\n\n**Laoding and parsing data**","metadata":{}},{"cell_type":"code","source":"#Loading the list of chopin's midi files as stream \nfilepath = \"../input/classical-music-midi/mozart/\"\n#Getting midi files\nall_midis = []\nfor i in os.listdir(filepath):\n    if i.endswith(\".mid\"):\n        print(i)\n        tr = filepath+i\n        midi = converter.parse(tr)\n        all_midis.append(midi)\n        \n# filepath = \"../input/classical-music-midi/mozart/\"\n# #Getting midi files\n# # all_midis= []\n# for i in os.listdir(filepath):\n#     if i.endswith(\".mid\"):\n#         print(i)\n#         tr = filepath+i\n#         midi = converter.parse(tr)\n#         all_midis.append(midi)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:10:40.445408Z","iopub.execute_input":"2022-03-30T13:10:40.446279Z","iopub.status.idle":"2022-03-30T13:15:40.562051Z","shell.execute_reply.started":"2022-03-30T13:10:40.446241Z","shell.execute_reply":"2022-03-30T13:15:40.561276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(all_midis[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:15:00.448726Z","iopub.status.idle":"2022-01-20T11:15:00.449175Z","shell.execute_reply.started":"2022-01-20T11:15:00.448949Z","shell.execute_reply":"2022-01-20T11:15:00.448969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Helping function        \ndef extract_notes(file):\n    notes = []\n    pick = None\n    for j in file:\n        print(j)\n        songs = instrument.partitionByInstrument(j)\n        for part in songs.parts:\n            pick = part.recurse()\n            for element in pick:\n#                 print(element)\n                if isinstance(element, note.Note):\n                    notes.append(str(element.pitch))\n                elif isinstance(element, chord.Chord):\n                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n#         break\n\n    return notes\n\n# extract_notes(all_midis)\n#Getting the list of notes as Corpus\n# Corpus = extract_notes(all_midis)\n# print(\"Total notes in all the Mozart midis in the dataset:\", len(Corpus))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:18:42.713187Z","iopub.execute_input":"2022-03-30T14:18:42.713466Z","iopub.status.idle":"2022-03-30T14:18:42.719729Z","shell.execute_reply.started":"2022-03-30T14:18:42.71342Z","shell.execute_reply":"2022-03-30T14:18:42.719024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Corpus[:200]","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:02:44.432323Z","iopub.execute_input":"2022-03-27T09:02:44.434244Z","iopub.status.idle":"2022-03-27T09:02:44.451187Z","shell.execute_reply.started":"2022-03-27T09:02:44.434203Z","shell.execute_reply":"2022-03-27T09:02:44.4505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **DATA EXPLORATION**</p>","metadata":{}},{"cell_type":"code","source":"print(\"First fifty values in the Corpus:\", Corpus[:50])","metadata":{"execution":{"iopub.status.busy":"2022-01-12T11:57:08.204013Z","iopub.execute_input":"2022-01-12T11:57:08.204288Z","iopub.status.idle":"2022-01-12T11:57:08.21161Z","shell.execute_reply.started":"2022-01-12T11:57:08.204259Z","shell.execute_reply":"2022-01-12T11:57:08.210611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First Lets write some functions that we need to look into the data\ndef show(music):\n    display(Image(str(music.write(\"lily.png\"))))\n    \ndef chords_n_notes(Snippet):\n    Melody = []\n    offset = 0 #Incremental\n    for i in Snippet:\n        #If it is chord\n        if (\".\" in i or i.isdigit()):\n            chord_notes = i.split(\".\") #Seperating the notes in chord\n            notes = [] \n            for j in chord_notes:\n                inst_note=int(j)\n                note_snip = note.Note(inst_note)            \n                notes.append(note_snip)\n                chord_snip = chord.Chord(notes)\n                chord_snip.offset = offset\n                Melody.append(chord_snip)\n        # pattern is a note\n        else: \n            note_snip = note.Note(i)\n            note_snip.offset = offset\n            Melody.append(note_snip)\n        # increase offset each iteration so that notes do not stack\n        offset += 1\n    Melody_midi = stream.Stream(Melody)   \n    return Melody_midi\n\n# Melody_Snippet = chords_n_notes(Corpus[:100])\n# show(Melody_Snippet)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:18:49.144054Z","iopub.execute_input":"2022-03-30T14:18:49.144342Z","iopub.status.idle":"2022-03-30T14:18:49.15467Z","shell.execute_reply.started":"2022-03-30T14:18:49.144309Z","shell.execute_reply":"2022-03-30T14:18:49.153696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Playing the above sheet music** \n\n*As I could not play a midi file on the Kaggle interface, I have created a \".wav\" filetype of the same outside of this code. I am using it to create an audio interface. Let us have a listen to the data corpus.* ","metadata":{}},{"cell_type":"code","source":"#to play audio or corpus\nprint(\"Sample Audio From Data\")\nIPython.display.Audio(\"../input/music-generated-lstm/Corpus_Snippet.wav\") ","metadata":{"execution":{"iopub.status.busy":"2022-01-12T11:51:49.35136Z","iopub.execute_input":"2022-01-12T11:51:49.351686Z","iopub.status.idle":"2022-01-12T11:51:49.582992Z","shell.execute_reply.started":"2022-01-12T11:51:49.351641Z","shell.execute_reply":"2022-01-12T11:51:49.581325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Examine all the notes in the Corpus** ","metadata":{}},{"cell_type":"code","source":"#Creating a count dictionary\ncount_num = Counter(Corpus)\nprint(\"Total unique notes in the Corpus:\", len(count_num))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:54.041305Z","iopub.execute_input":"2022-03-30T13:15:54.04167Z","iopub.status.idle":"2022-03-30T13:15:54.054802Z","shell.execute_reply.started":"2022-03-30T13:15:54.041635Z","shell.execute_reply":"2022-03-30T13:15:54.052852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploring the notes dictionary\nNotes = list(count_num.keys())\nRecurrence = list(count_num.values())\n#Average recurrenc for a note in Corpus\ndef Average(lst):\n    return sum(lst) / len(lst)\nprint(\"Average recurrenc for a note in Corpus:\", Average(Recurrence))\nprint(\"Most frequent note in Corpus appeared:\", max(Recurrence), \"times\")\nprint(\"Least frequent note in Corpus appeared:\", min(Recurrence), \"time\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:54.056227Z","iopub.execute_input":"2022-03-30T13:15:54.056537Z","iopub.status.idle":"2022-03-30T13:15:54.06696Z","shell.execute_reply.started":"2022-03-30T13:15:54.0565Z","shell.execute_reply":"2022-03-30T13:15:54.066277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, there are some very rare notes in the melody; some so rare that it was played only once in the whole data. This would create a lot of problems. (I did run into most of them while writing this piece)\nTo spare us the error reports, let us have a look at the frequency of the notes. \nAnd for simplicity, I shall be eliminating some of the least occurring notes. I am sure Chopin wouldn't mind me messing with his masterpiece for science or would he? Either way, I may never know!   ","metadata":{}},{"cell_type":"code","source":"# Plotting the distribution of Notes\nplt.figure(figsize=(18,3),facecolor=\"#97BACB\")\nbins = np.arange(0,(max(Recurrence)), 50) \nplt.hist(Recurrence, bins=bins, color=\"#97BACB\")\nplt.axvline(x=100,color=\"#DBACC1\")\nplt.title(\"Frequency Distribution Of Notes In The Corpus\")\nplt.xlabel(\"Frequency Of Chords in Corpus\")\nplt.ylabel(\"Number Of Chords\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:54.068239Z","iopub.execute_input":"2022-03-30T13:15:54.068611Z","iopub.status.idle":"2022-03-30T13:15:54.42791Z","shell.execute_reply.started":"2022-03-30T13:15:54.068538Z","shell.execute_reply":"2022-03-30T13:15:54.427208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have decided, I will be taking out the notes that were played less than 100 times. I mean, if Chopin liked them he would have played it a lot more often. So I create a list of rare notes in the next section. ","metadata":{}},{"cell_type":"code","source":"#Getting a list of rare chords\nrare_note = []\nfor index, (key, value) in enumerate(count_num.items()):\n    if value < 100:\n        m =  key\n        rare_note.append(m)\n        \nprint(\"Total number of notes that occur less than 100 times:\", len(rare_note))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:54.430855Z","iopub.execute_input":"2022-03-30T13:15:54.431378Z","iopub.status.idle":"2022-03-30T13:15:54.438925Z","shell.execute_reply.started":"2022-03-30T13:15:54.431337Z","shell.execute_reply":"2022-03-30T13:15:54.438124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Eleminating the rare notes\nfor element in Corpus:\n    if element in rare_note:\n        Corpus.remove(element)\n\nprint(\"Length of Corpus after elemination the rare notes:\", len(Corpus))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:54.440307Z","iopub.execute_input":"2022-03-30T13:15:54.440721Z","iopub.status.idle":"2022-03-30T13:15:55.692946Z","shell.execute_reply.started":"2022-03-30T13:15:54.440687Z","shell.execute_reply":"2022-03-30T13:15:55.692163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **DATA PREPROCESSING**</p>\n\nNotes in music can be described as sound waves with specific combinations of frequency and wavelength. The names of these notes are stored in our database, and when we loaded the data, we used the music21 library from MIT to retrieve additional information such as frequency, wavelength, and duration for each note.\n\n\n**This section will comprise of the follwoing tasks-**\n\n**Creating a dictionary**: We are establishing a dictionary to establish a mapping between musical notes and their corresponding indices. In our dataset, the notes are represented as strings, but for the computer, they are merely symbols. Thus, we create a dictionary to associate each unique note in our dataset with a numerical value. This enables us to encode and decode information when utilizing the Recurrent Neural Network (RNN).\n\n**Encoding and Splitting the corpus**: The next step involves encoding and dividing the dataset into smaller sequences of the same length. At this stage, the dataset consists of musical notes. We encode these notes and generate sequences with consistent lengths, containing both features and their corresponding targets. Each feature and target are represented by the mapped index from the dictionary, representing the unique characters.\n\n**Assigning X and Y**: Following that, we resize and normalize the labels while applying one-hot encoding to the targets. This prepares the data to be fed into the RNN for training. However, prior to that, we need to construct the RNN model.\n\n**Splitting Train and Seed datasets**: To generate music, we need to provide some initial input to the RNN. Therefore, we set aside a portion of the data as \"seeds\" for this purpose. While it would be possible to train the model using the entire dataset, I, as a non-musician, lack the ability to determine an appropriate input seed value.\n\n**Creating a list of sorted unique characters**: This involves generating a list containing all the distinct characters found in the dataset. The characters are sorted in a particular order within the list.\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Storing all the unique characters present in my corpus to bult a mapping dic. \nsymb = sorted(list(set(Corpus)))\n\nL_corpus = len(Corpus) #length of corpus\nL_symb = len(symb) #length of total unique characters\n\n#Building dictionary to access the vocabulary from indices and vice versa\nmapping = dict((c, i) for i, c in enumerate(symb))\nreverse_mapping = dict((i, c) for i, c in enumerate(symb))\n\nprint(\"Total number of characters:\", L_corpus)\nprint(\"Number of unique characters:\", L_symb)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:55.694277Z","iopub.execute_input":"2022-03-30T13:15:55.69454Z","iopub.status.idle":"2022-03-30T13:15:55.705769Z","shell.execute_reply.started":"2022-03-30T13:15:55.694506Z","shell.execute_reply":"2022-03-30T13:15:55.705096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoding and Splitting the Corpus as Labels and Targets**","metadata":{}},{"cell_type":"code","source":"Corpus[:50]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:32:19.118507Z","iopub.execute_input":"2022-01-11T10:32:19.11905Z","iopub.status.idle":"2022-01-11T10:32:19.129899Z","shell.execute_reply.started":"2022-01-11T10:32:19.119012Z","shell.execute_reply":"2022-01-11T10:32:19.129178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the Corpus in equal length of strings and output target\nlength = 40\nfeatures = []\ntargets = []\nfor i in range(0, L_corpus - length, 1):\n    feature = Corpus[i:i + length]\n    target = Corpus[i + length]\n    features.append([mapping[j] for j in feature])\n    targets.append(mapping[target])\n    \n    \nL_datapoints = len(targets)\nprint(\"Total number of sequences in the Corpus:\", L_datapoints)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:15:55.708974Z","iopub.execute_input":"2022-03-30T13:15:55.709237Z","iopub.status.idle":"2022-03-30T13:15:55.977054Z","shell.execute_reply.started":"2022-03-30T13:15:55.709202Z","shell.execute_reply":"2022-03-30T13:15:55.976188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features[:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:32:19.390453Z","iopub.execute_input":"2022-01-11T10:32:19.390927Z","iopub.status.idle":"2022-01-11T10:32:19.405071Z","shell.execute_reply.started":"2022-01-11T10:32:19.390887Z","shell.execute_reply":"2022-01-11T10:32:19.404188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_bin(x):\n    fin = \"\"\n    a = bin(x)[2:]\n    for _ in range(8-len(a)): fin+='0'\n    fin+=a\n    ans = []\n    for ch in fin:ans.append(int(ch))\n    return torch.tensor(ans)\n\nto_bin(169)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:19:00.933241Z","iopub.execute_input":"2022-03-30T14:19:00.933607Z","iopub.status.idle":"2022-03-30T14:19:00.97114Z","shell.execute_reply.started":"2022-03-30T14:19:00.933571Z","shell.execute_reply":"2022-03-30T14:19:00.970519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape X and normalize\nX = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n# one hot encode the output variable\n# y = tensorflow.keras.utils.to_categorical(targets)\ny = (torch.tensor(targets))\n# y = np.float(y)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:55:01.245395Z","iopub.execute_input":"2022-03-30T13:55:01.245919Z","iopub.status.idle":"2022-03-30T13:55:01.749126Z","shell.execute_reply.started":"2022-03-30T13:55:01.245875Z","shell.execute_reply":"2022-03-30T13:55:01.748329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tt = (np.reshape(features, (L_datapoints, length, 1)))\nX_trans = torch.randn(X_tt.shape[0], X_tt.shape[1], 8)#torch.load('../input/trans-test/X_trans.pt')t","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:19:24.775264Z","iopub.execute_input":"2022-03-30T13:19:24.775994Z","iopub.status.idle":"2022-03-30T13:19:25.399963Z","shell.execute_reply.started":"2022-03-30T13:19:24.775957Z","shell.execute_reply":"2022-03-30T13:19:25.39923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(X_tt.shape[0]):\n    for j in range(X_tt.shape[1]):\n        X_trans[i][j] = to_bin(X_tt[i][j][0])\n#         print(X_trans[i][j])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:19:26.047912Z","iopub.execute_input":"2022-03-30T13:19:26.048783Z","iopub.status.idle":"2022-03-30T13:20:12.385685Z","shell.execute_reply.started":"2022-03-30T13:19:26.048729Z","shell.execute_reply":"2022-03-30T13:20:12.384931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:55:08.003831Z","iopub.execute_input":"2022-03-30T13:55:08.004096Z","iopub.status.idle":"2022-03-30T13:55:08.009564Z","shell.execute_reply.started":"2022-03-30T13:55:08.004067Z","shell.execute_reply":"2022-03-30T13:55:08.008596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking out a subset of data to be used as seed\n#Change X and X_trans depending upon model to use \n# X_train, X_seed, y_train, y_seed = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n\ntrain_ds = torch.load('../input/trans-test/train_ds.pt')#[]\ntest_ds = torch.load('../input/trans-test/test_ds.pt')#[]\n\n# for i in range(len(X_train)):\n#     train_ds.append([X_train[i], y_train[i]])\n    \n# for i in range(len(X_seed)):\n#     test_ds.append([X_seed[i], y_seed[i]])\n    \ntrain_dl = DataLoader(train_ds, batch_size = 256, shuffle = True)\ntest_dl = DataLoader(test_ds, batch_size = 256, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:20:36.5545Z","iopub.execute_input":"2022-03-30T14:20:36.555055Z","iopub.status.idle":"2022-03-30T14:20:40.118098Z","shell.execute_reply.started":"2022-03-30T14:20:36.555021Z","shell.execute_reply":"2022-03-30T14:20:40.117356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x,y in train_dl:\n    print(x.shape)\n    print(y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:20:44.184943Z","iopub.execute_input":"2022-03-30T14:20:44.185199Z","iopub.status.idle":"2022-03-30T14:20:44.213952Z","shell.execute_reply.started":"2022-03-30T14:20:44.185172Z","shell.execute_reply":"2022-03-30T14:20:44.213184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(train_ds, 'train_ds.pt')\ntorch.save(test_ds, 'test_ds.pt')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:08:41.186107Z","iopub.execute_input":"2022-03-30T14:08:41.186383Z","iopub.status.idle":"2022-03-30T14:08:43.657517Z","shell.execute_reply.started":"2022-03-30T14:08:41.186353Z","shell.execute_reply":"2022-03-30T14:08:43.656699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting Train and Seed datasets**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **MODEL BUILDING**</p>","metadata":{}},{"cell_type":"code","source":"#Initialising the Model\nmodel = Sequential()\n#Adding layers\nmodel.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.1))\nmodel.add(LSTM(256))\nmodel.add(Dense(256))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(y.shape[1], activation='softmax'))\n#Compiling the model for training  \nopt = Adamax(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-06T10:50:00.161945Z","iopub.execute_input":"2022-01-06T10:50:00.162457Z","iopub.status.idle":"2022-01-06T10:50:03.219525Z","shell.execute_reply.started":"2022-01-06T10:50:00.162406Z","shell.execute_reply":"2022-01-06T10:50:03.218758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nn.Sequential(\n        nn.LSTM(1, 512, 2, batch_first=True, dropout = 0.1),\n        nn.LSTM(1, 256, 1, batch_first=True, dropout = 0.1)\n    \n        )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.LSTM(1, 512, 1, batch_first=True, dropout=0.1)\n        self.l2 = nn.LSTM(512, 256, 1, batch_first=True, dropout=0.1)\n        self.d = nn.Linear(256, 266)\n        \n    def forward(self, x):\n        out, (hn, _) = self.l1(x.float())\n        out, (hn, _) = self.l2(out)\n        output = self.d(hn)\n        \n        output = output.reshape(output.shape[1], output.shape[2])\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-01-12T11:14:59.135443Z","iopub.execute_input":"2022-01-12T11:14:59.136181Z","iopub.status.idle":"2022-01-12T11:14:59.142551Z","shell.execute_reply.started":"2022-01-12T11:14:59.136145Z","shell.execute_reply":"2022-01-12T11:14:59.141872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.LSTM(1, 128, 1, batch_first=True, dropout=0.1)\n        self.l2 = nn.LSTM(128, 256, 1, batch_first=True, dropout=0.1)\n        self.p = nn.Linear(256,256)\n        self.d = nn.Linear(256, 266)\n        self.drop = nn.Dropout(p=0.1)\n        \n    def forward(self, x):\n        out, (hn, _) = self.l1(x.float())\n#         print(out.shape, hn.shape)\n        out = self.drop(out)\n        out, (hn, _) = self.l2(out)\n        hn = self.drop(hn)\n        output = self.p(hn)\n        output = self.drop(output)\n        output = self.d(output)\n        \n        output = output.reshape(output.shape[1], output.shape[2])\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-01-12T11:14:59.470767Z","iopub.execute_input":"2022-01-12T11:14:59.471269Z","iopub.status.idle":"2022-01-12T11:14:59.480004Z","shell.execute_reply.started":"2022-01-12T11:14:59.471233Z","shell.execute_reply":"2022-01-12T11:14:59.479282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.LSTM(1, 64, 1, batch_first=True, bidirectional = True)\n        self.l2 = nn.LSTM(128, 256, 1, batch_first=True)\n        self.p = nn.Linear(256,256)\n        self.d = nn.Linear(256, 269)\n        self.drop = nn.Dropout(p=0.1)\n        \n    def forward(self, x):\n        out, (hn, _) = self.l1(x.float())\n#         print(out.shape, hn.shape)\n        out = self.drop(out)\n        out, (hn, _) = self.l2(out)\n#         print(out.shape, hn.shape)\n#         hn = hn.reshape(-1, 1, 512)\n#         print(hn.shape)\n        hn = self.drop(hn)\n        output = self.p(hn)\n        output = self.drop(output)\n        output = self.d(output)\n#         print(output.shape)\n        \n        output = output.reshape(output.shape[1], output.shape[2])\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-01-12T11:59:42.477554Z","iopub.execute_input":"2022-01-12T11:59:42.478278Z","iopub.status.idle":"2022-01-12T11:59:42.486225Z","shell.execute_reply.started":"2022-01-12T11:59:42.478239Z","shell.execute_reply":"2022-01-12T11:59:42.485532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.models import load_model, Model\nfrom tensorflow import keras\n\n# from attention import Attention\n\nmodel_input = Input(shape=(40, 8))\nx = LSTM(64, return_sequences=True)(model_input)\nx = Attention(units=32)(x)\nx = Dense(169)(x)\nmodel = Model(model_input, x)\n\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3, name=\"Adam\")\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[tf.keras.losses.CategoricalCrossentropy()])\nmodel.summary()\n\n# opt = keras.optimizers.Adam(learning_rate=1e-4)\n# model.compile(loss='categorical_crossentropy', optimizer=opt)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:49:22.169178Z","iopub.execute_input":"2022-03-30T13:49:22.169458Z","iopub.status.idle":"2022-03-30T13:49:22.427231Z","shell.execute_reply.started":"2022-03-30T13:49:22.169409Z","shell.execute_reply":"2022-03-30T13:49:22.426502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train.numpy(), y_train.numpy(), validation_split=0.2, epochs=30, batch_size=256,\n          verbose=1, callbacks=[reduce_lr, early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T13:50:30.435865Z","iopub.execute_input":"2022-03-30T13:50:30.436129Z","iopub.status.idle":"2022-03-30T13:50:44.113665Z","shell.execute_reply.started":"2022-03-30T13:50:30.436103Z","shell.execute_reply":"2022-03-30T13:50:44.112957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class trans(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 256, 40, 32\n        self.el1 = nn.TransformerEncoderLayer(d_model=16, nhead=4)\n        self.lstm = nn.LSTM(8, 16, 1, batch_first=True)\n        self.drop = nn.Dropout(p=0.1)\n        # 320\n        self.mlp = nn.Sequential(nn.Linear(640, 256), nn.Linear(256, 169))\n        \n    def forward(self, x):\n        out, (_, _)  = self.lstm(x)\n        out = self.drop(out)\n        out = self.el1(out)\n        out = self.drop(out)\n        out = nn.Flatten()(out)\n#         print(out.shape)\n        output = self.mlp(out)\n#         print(output.shape)\n#         output = output.reshape(output.shape[1], output.shape[2])\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:20:53.935878Z","iopub.execute_input":"2022-03-30T14:20:53.936477Z","iopub.status.idle":"2022-03-30T14:20:53.944177Z","shell.execute_reply.started":"2022-03-30T14:20:53.936419Z","shell.execute_reply":"2022-03-30T14:20:53.942957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = trans().to(device)\nx = torch.randn(256,40,8).to(device)\ny = model(x)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:21:03.529065Z","iopub.execute_input":"2022-03-30T14:21:03.529327Z","iopub.status.idle":"2022-03-30T14:21:03.635895Z","shell.execute_reply.started":"2022-03-30T14:21:03.529298Z","shell.execute_reply":"2022-03-30T14:21:03.635053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:06:23.577031Z","iopub.execute_input":"2022-03-30T14:06:23.577285Z","iopub.status.idle":"2022-03-30T14:06:23.59947Z","shell.execute_reply.started":"2022-03-30T14:06:23.577259Z","shell.execute_reply":"2022-03-30T14:06:23.598456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:06:26.69624Z","iopub.execute_input":"2022-03-30T14:06:26.696811Z","iopub.status.idle":"2022-03-30T14:06:26.704163Z","shell.execute_reply.started":"2022-03-30T14:06:26.696773Z","shell.execute_reply":"2022-03-30T14:06:26.703235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x,y in train_dl:\n    print((y[0][0]))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:43:21.536643Z","iopub.execute_input":"2022-01-08T10:43:21.537009Z","iopub.status.idle":"2022-01-08T10:43:21.554963Z","shell.execute_reply.started":"2022-01-08T10:43:21.536978Z","shell.execute_reply":"2022-01-08T10:43:21.554018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp = torch.randn(32, 40, 8).to(device)\ny = model(inp)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-27T10:17:11.304515Z","iopub.execute_input":"2022-03-27T10:17:11.304957Z","iopub.status.idle":"2022-03-27T10:17:11.319109Z","shell.execute_reply.started":"2022-03-27T10:17:11.304923Z","shell.execute_reply":"2022-03-27T10:17:11.318325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = torch.optim.Adamax(model.parameters(), lr = 0.001)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T10:05:48.35512Z","iopub.execute_input":"2022-03-27T10:05:48.355651Z","iopub.status.idle":"2022-03-27T10:05:48.362724Z","shell.execute_reply.started":"2022-03-27T10:05:48.355597Z","shell.execute_reply":"2022-03-27T10:05:48.362087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader)\n    model.train()\n    for batch_data,(x,y) in enumerate(dataloader):\n        x,y = x.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(x)\n#         print(pred.shape, y.shape)\n        loss = loss_fn(pred,y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if batch_data % 100 == 0:\n            loss, current = loss.item(), batch_data * len(x)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n            \n# model = Summary_CNN()\n# opt = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# loss_fn = F.mse_loss\n\n# for epoch in range(50):\n#   train(test_dl, model, loss_fn=loss_fn, optimizer=opt)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:21:20.525367Z","iopub.execute_input":"2022-03-30T14:21:20.526Z","iopub.status.idle":"2022-03-30T14:21:20.532014Z","shell.execute_reply.started":"2022-03-30T14:21:20.525962Z","shell.execute_reply":"2022-03-30T14:21:20.531336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = trans().to(device)\n\nopt = torch.optim.Adamax(model.parameters(), lr = 1e-4)\nloss_fn = nn.CrossEntropyLoss()\n\nfor epoch in range(30):\n    print(epoch+1)\n    train(train_dl, model, loss_fn=loss_fn, optimizer=opt)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:24:49.402223Z","iopub.execute_input":"2022-03-30T14:24:49.402513Z","iopub.status.idle":"2022-03-30T14:25:44.067315Z","shell.execute_reply.started":"2022-03-30T14:24:49.402482Z","shell.execute_reply":"2022-03-30T14:25:44.066469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model's Summary               \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T10:50:08.128001Z","iopub.execute_input":"2022-01-06T10:50:08.128785Z","iopub.status.idle":"2022-01-06T10:50:08.138477Z","shell.execute_reply.started":"2022-01-06T10:50:08.12874Z","shell.execute_reply":"2022-01-06T10:50:08.137664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the Model\nhistory = model.fit(X_train, y_train, batch_size=256, epochs=200)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-06T10:50:42.634296Z","iopub.execute_input":"2022-01-06T10:50:42.634569Z","iopub.status.idle":"2022-01-06T10:53:25.655952Z","shell.execute_reply.started":"2022-01-06T10:50:42.634536Z","shell.execute_reply":"2022-01-06T10:53:25.654617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-color:#f2efcb;font-family:arial;color:#7a2500;font-size:100%;text-align:center;border-radius:40px 40px; padding : 10px\"> **EVALUATING MODELS**</p>","metadata":{}},{"cell_type":"code","source":"#Plotting the learnings \nhistory_df = pd.DataFrame(history.history)\nfig = plt.figure(figsize=(15,4), facecolor=\"#97BACB\")\nfig.suptitle(\"Learning Plot of Model for Loss\")\npl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\npl.set(ylabel =\"Training Loss\")\npl.set(xlabel =\"Epochs\")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:02:24.805085Z","iopub.execute_input":"2022-01-08T11:02:24.805507Z","iopub.status.idle":"2022-01-08T11:02:24.836178Z","shell.execute_reply.started":"2022-01-08T11:02:24.805461Z","shell.execute_reply":"2022-01-08T11:02:24.833873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generating the Melody**\n\nA function to obtain the generated music","metadata":{}},{"cell_type":"code","source":"from random import choices\n\ndef Malody_Generator(Note_count):\n    seed = X_seed[np.random.randint(0,len(X_seed)-1)]\n    Music = \"\"\n    Notes_Generated=[]\n    for i in range(100):\n        seed = seed.reshape(1,length,1)\n        seedt = torch.tensor(seed).to(device)\n        prediction = model(seedt)\n        prediction = F.softmax(prediction)\n#         print(prediction.shape)\n        index = choices(range(269), weights = prediction[0], k=1)[0]\n#         print(index)\n#         print(prediction.shape)\n#         prediction = np.log(prediction) / 1.0 #diversity\n#         exp_preds = np.exp(prediction)\n#         prediction = exp_preds / np.sum(exp_preds)\n#         index = prediction\n        index_N = index/ float(L_symb)   \n        Notes_Generated.append(index)\n        Music = [reverse_mapping[char] for char in Notes_Generated]\n        seed = np.insert(seed[0],len(seed[0]),index_N)\n        seed = seed[1:]\n    #Now, we have music in form or a list of chords and notes and we want to be a midi file.\n    Melody = chords_n_notes(Music)\n    Melody_midi = stream.Stream(Melody)   \n    return Music,Melody_midi\n\n\n#getting the Notes and Melody created by the model\nMusic_notes, Melody = Malody_Generator(100)\nshow(Melody)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T12:10:42.593006Z","iopub.execute_input":"2022-01-12T12:10:42.593275Z","iopub.status.idle":"2022-01-12T12:10:44.275752Z","shell.execute_reply.started":"2022-01-12T12:10:42.593248Z","shell.execute_reply":"2022-01-12T12:10:44.274939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This sure looks like music! To check if it sounds like music we have to listen to the MIDI file. Playing midi is crumblesome. I have saved and converted a few generated melodies to \".wav\" format outside of this notebook. So let us have a listen. \n\n**Melody Generated Sample 1**","metadata":{}},{"cell_type":"code","source":"#To save the generated melody\nMelody.write('midi','Melody_Generated_khichdi.mid')\n#to play audio or corpus\n# IPython.display.Audio(\"../input/music-generated-lstm/Melody_Generated 2.wav\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T12:11:40.712169Z","iopub.execute_input":"2022-01-12T12:11:40.712438Z","iopub.status.idle":"2022-01-12T12:11:40.757381Z","shell.execute_reply.started":"2022-01-12T12:11:40.712409Z","shell.execute_reply":"2022-01-12T12:11:40.756557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Melody Generated Sample 2**","metadata":{}},{"cell_type":"code","source":"#to play audio or corpus\nIPython.display.Audio(\"../input/music-generated-lstm/Melody_Generated_1.wav\")","metadata":{"execution":{"iopub.status.busy":"2022-01-06T10:56:13.68683Z","iopub.execute_input":"2022-01-06T10:56:13.687463Z","iopub.status.idle":"2022-01-06T10:56:14.406267Z","shell.execute_reply.started":"2022-01-06T10:56:13.687422Z","shell.execute_reply":"2022-01-06T10:56:14.405459Z"},"trusted":true},"execution_count":null,"outputs":[]}]}